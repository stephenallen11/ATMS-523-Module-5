{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATMS 523 Homework 5: Radar Parameter Rain Rate Prediction\n",
    "## Stephen Allen\n",
    "This notebook implements multiple machine learning models to predict rain rate from polarimetric radar parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('radar_parameters.csv', index_col=0)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nDataset info:\")\n",
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "df.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(df.columns):\n",
    "    axes[idx].hist(df[col], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].set_title(f'Distribution of {col}')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix of Radar Parameters and Rain Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split (70-30)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "feature_columns = ['Zh (dBZ)', 'Zdr (dB)', 'Ldr (dB)', 'Kdp (deg km-1)', 'Ah (dBZ/km)', 'Adr (dB/km)']\n",
    "target_column = 'R (mm/hr)'\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_column]\n",
    "\n",
    "# Perform 70-30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nFeatures: {feature_columns}\")\n",
    "print(f\"Target: {target_column}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline Model: Z-R Relationship\n",
    "\n",
    "The baseline uses the formula: $Z = 200R^{1.6}$\n",
    "\n",
    "To predict R from Z, we rearrange: $R = (Z/200)^{1/1.6}$\n",
    "\n",
    "where $Z = 10^{dBZ/10}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rain_rate_from_zh(zh_dbz):\n",
    "    \"\"\"\n",
    "    Predict rain rate using the Z-R relationship: Z = 200R^1.6\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    zh_dbz : array-like\n",
    "        Radar reflectivity in dBZ\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    R : array-like\n",
    "        Predicted rain rate in mm/hr\n",
    "    \"\"\"\n",
    "    # Convert dBZ to linear Z\n",
    "    Z = 10 ** (zh_dbz / 10)\n",
    "    \n",
    "    # Calculate R from Z = 200R^1.6\n",
    "    # R = (Z/200)^(1/1.6)\n",
    "    R = (Z / 200) ** (1 / 1.6)\n",
    "    \n",
    "    return R\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using baseline model\n",
    "y_train_pred_baseline = predict_rain_rate_from_zh(X_train['Zh (dBZ)'])\n",
    "y_test_pred_baseline = predict_rain_rate_from_zh(X_test['Zh (dBZ)'])\n",
    "\n",
    "# Calculate metrics\n",
    "baseline_train_r2 = r2_score(y_train, y_train_pred_baseline)\n",
    "baseline_test_r2 = r2_score(y_test, y_test_pred_baseline)\n",
    "baseline_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_baseline))\n",
    "baseline_test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred_baseline))\n",
    "\n",
    "print(\"Baseline Model (Z-R Relationship) Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training R\u00b2: {baseline_train_r2:.4f}\")\n",
    "print(f\"Testing R\u00b2: {baseline_test_r2:.4f}\")\n",
    "print(f\"Training RMSE: {baseline_train_rmse:.4f} mm/hr\")\n",
    "print(f\"Testing RMSE: {baseline_test_rmse:.4f} mm/hr\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Linear Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train linear regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_lr = lr_model.predict(X_train)\n",
    "y_test_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "lr_train_r2 = r2_score(y_train, y_train_pred_lr)\n",
    "lr_test_r2 = r2_score(y_test, y_test_pred_lr)\n",
    "lr_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_lr))\n",
    "lr_test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred_lr))\n",
    "\n",
    "print(\"Linear Regression Model Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training R\u00b2: {lr_train_r2:.4f}\")\n",
    "print(f\"Testing R\u00b2: {lr_test_r2:.4f}\")\n",
    "print(f\"Training RMSE: {lr_train_rmse:.4f} mm/hr\")\n",
    "print(f\"Testing RMSE: {lr_test_rmse:.4f} mm/hr\")\n",
    "\n",
    "print(\"\\nModel Coefficients:\")\n",
    "for feature, coef in zip(feature_columns, lr_model.coef_):\n",
    "    print(f\"{feature}: {coef:.6f}\")\n",
    "print(f\"Intercept: {lr_model.intercept_:.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Polynomial Regression with Grid Search\n",
    "Grid search over polynomial orders 0-9 with 7-fold cross-validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for polynomial regression\n",
    "poly_pipeline = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures()),\n",
    "    ('linear_regression', LinearRegression())\n",
    "])\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_poly = {\n",
    "    'poly_features__degree': list(range(0, 10))  # 0-9\n",
    "}\n",
    "\n",
    "# Perform grid search with 7-fold cross-validation\n",
    "print(\"Performing grid search for polynomial regression...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "grid_search_poly = GridSearchCV(\n",
    "    poly_pipeline,\n",
    "    param_grid_poly,\n",
    "    cv=7,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_poly.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nGrid search complete!\")\n",
    "print(f\"Best polynomial degree: {grid_search_poly.best_params_['poly_features__degree']}\")\n",
    "print(f\"Best cross-validation R\u00b2: {grid_search_poly.best_score_:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all cross-validation results\n",
    "cv_results_poly = pd.DataFrame(grid_search_poly.cv_results_)\n",
    "print(\"\\nCross-validation results for all polynomial orders:\")\n",
    "print(cv_results_poly[['param_poly_features__degree', 'mean_test_score', 'std_test_score']].to_string(index=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize polynomial degree vs R\u00b2\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(cv_results_poly['param_poly_features__degree'], \n",
    "         cv_results_poly['mean_test_score'], \n",
    "         marker='o', linestyle='-', linewidth=2, markersize=8)\n",
    "plt.fill_between(cv_results_poly['param_poly_features__degree'],\n",
    "                 cv_results_poly['mean_test_score'] - cv_results_poly['std_test_score'],\n",
    "                 cv_results_poly['mean_test_score'] + cv_results_poly['std_test_score'],\n",
    "                 alpha=0.2)\n",
    "plt.xlabel('Polynomial Degree', fontsize=12)\n",
    "plt.ylabel('Mean Cross-Validation R\u00b2', fontsize=12)\n",
    "plt.title('Polynomial Degree vs Model Performance', fontsize=14)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xticks(range(0, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model and make predictions\n",
    "best_poly_model = grid_search_poly.best_estimator_\n",
    "y_train_pred_poly = best_poly_model.predict(X_train)\n",
    "y_test_pred_poly = best_poly_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "poly_train_r2 = r2_score(y_train, y_train_pred_poly)\n",
    "poly_test_r2 = r2_score(y_test, y_test_pred_poly)\n",
    "poly_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_poly))\n",
    "poly_test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred_poly))\n",
    "\n",
    "print(f\"Best Polynomial Regression Model (degree={grid_search_poly.best_params_['poly_features__degree']}) Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training R\u00b2: {poly_train_r2:.4f}\")\n",
    "print(f\"Testing R\u00b2: {poly_test_r2:.4f}\")\n",
    "print(f\"Training RMSE: {poly_train_rmse:.4f} mm/hr\")\n",
    "print(f\"Testing RMSE: {poly_test_rmse:.4f} mm/hr\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Forest Regressor with Grid Search\n",
    "Grid search over specified hyperparameters with cross-validation.\n",
    "**Note**: This will be computationally intensive and may take several minutes to complete.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"max_depth\": [10, 100],\n",
    "    \"max_features\": [\"sqrt\", 1.0],\n",
    "    \"min_samples_leaf\": [1, 4],\n",
    "    \"min_samples_split\": [2, 10],\n",
    "    \"n_estimators\": [200, 1000]\n",
    "}\n",
    "\n",
    "# Calculate total number of combinations\n",
    "total_combinations = np.prod([len(v) for v in param_grid_rf.values()])\n",
    "print(f\"Total parameter combinations to test: {total_combinations}\")\n",
    "print(\"\\nPerforming grid search for Random Forest...\")\n",
    "print(\"This will take several minutes. Progress will be displayed...\")\n",
    "print(\"=\"*70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search with cross-validation\n",
    "rf_base = RandomForestRegressor(random_state=42)\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    rf_base,\n",
    "    param_grid_rf,\n",
    "    cv=7,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nGrid search complete!\")\n",
    "print(\"\\nBest parameters found:\")\n",
    "for param, value in grid_search_rf.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "print(f\"\\nBest cross-validation R\u00b2: {grid_search_rf.best_score_:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model and make predictions\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "y_train_pred_rf = best_rf_model.predict(X_train)\n",
    "y_test_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "rf_train_r2 = r2_score(y_train, y_train_pred_rf)\n",
    "rf_test_r2 = r2_score(y_test, y_test_pred_rf)\n",
    "rf_train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred_rf))\n",
    "rf_test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred_rf))\n",
    "\n",
    "print(\"Best Random Forest Model Performance:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Training R\u00b2: {rf_train_r2:.4f}\")\n",
    "print(f\"Testing R\u00b2: {rf_test_r2:.4f}\")\n",
    "print(f\"Training RMSE: {rf_train_rmse:.4f} mm/hr\")\n",
    "print(f\"Testing RMSE: {rf_test_rmse:.4f} mm/hr\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': best_rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance from Random Forest:\")\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Visualize feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Importance in Random Forest Model', fontsize=14)\n",
    "plt.grid(alpha=0.3, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison and Results Summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison table\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': [\n",
    "        'Baseline (Z-R)',\n",
    "        'Linear Regression',\n",
    "        f'Polynomial (degree={grid_search_poly.best_params_[\"poly_features__degree\"]})',\n",
    "        'Random Forest'\n",
    "    ],\n",
    "    'Train R\u00b2': [\n",
    "        baseline_train_r2,\n",
    "        lr_train_r2,\n",
    "        poly_train_r2,\n",
    "        rf_train_r2\n",
    "    ],\n",
    "    'Test R\u00b2': [\n",
    "        baseline_test_r2,\n",
    "        lr_test_r2,\n",
    "        poly_test_r2,\n",
    "        rf_test_r2\n",
    "    ],\n",
    "    'Train RMSE': [\n",
    "        baseline_train_rmse,\n",
    "        lr_train_rmse,\n",
    "        poly_train_rmse,\n",
    "        rf_train_rmse\n",
    "    ],\n",
    "    'Test RMSE': [\n",
    "        baseline_test_rmse,\n",
    "        lr_test_rmse,\n",
    "        poly_test_rmse,\n",
    "        rf_test_rmse\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# R\u00b2 comparison\n",
    "x_pos = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x_pos - width/2, results_df['Train R\u00b2'], width, label='Train R\u00b2', alpha=0.8)\n",
    "axes[0].bar(x_pos + width/2, results_df['Test R\u00b2'], width, label='Test R\u00b2', alpha=0.8)\n",
    "axes[0].set_ylabel('R\u00b2 Score', fontsize=12)\n",
    "axes[0].set_title('R\u00b2 Score Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(results_df['Model'], rotation=15, ha='right')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3, axis='y')\n",
    "\n",
    "# RMSE comparison\n",
    "axes[1].bar(x_pos - width/2, results_df['Train RMSE'], width, label='Train RMSE', alpha=0.8)\n",
    "axes[1].bar(x_pos + width/2, results_df['Test RMSE'], width, label='Test RMSE', alpha=0.8)\n",
    "axes[1].set_ylabel('RMSE (mm/hr)', fontsize=12)\n",
    "axes[1].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(results_df['Model'], rotation=15, ha='right')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs Actual plots for all models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "predictions = [\n",
    "    (y_test_pred_baseline, 'Baseline (Z-R)', baseline_test_r2, baseline_test_rmse),\n",
    "    (y_test_pred_lr, 'Linear Regression', lr_test_r2, lr_test_rmse),\n",
    "    (y_test_pred_poly, f'Polynomial (degree={grid_search_poly.best_params_[\"poly_features__degree\"]})', poly_test_r2, poly_test_rmse),\n",
    "    (y_test_pred_rf, 'Random Forest', rf_test_r2, rf_test_rmse)\n",
    "]\n",
    "\n",
    "for idx, (y_pred, model_name, r2, rmse) in enumerate(predictions):\n",
    "    axes[idx].scatter(y_test, y_pred, alpha=0.3, s=10)\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = min(y_test.min(), y_pred.min())\n",
    "    max_val = max(y_test.max(), y_pred.max())\n",
    "    axes[idx].plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "    \n",
    "    axes[idx].set_xlabel('Actual Rain Rate (mm/hr)', fontsize=11)\n",
    "    axes[idx].set_ylabel('Predicted Rain Rate (mm/hr)', fontsize=11)\n",
    "    axes[idx].set_title(f'{model_name}\\nR\u00b2 = {r2:.4f}, RMSE = {rmse:.4f} mm/hr', fontsize=12, fontweight='bold')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plots for all models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, (y_pred, model_name, r2, rmse) in enumerate(predictions):\n",
    "    residuals = y_test - y_pred\n",
    "    \n",
    "    axes[idx].scatter(y_pred, residuals, alpha=0.3, s=10)\n",
    "    axes[idx].axhline(y=0, color='r', linestyle='--', linewidth=2)\n",
    "    \n",
    "    axes[idx].set_xlabel('Predicted Rain Rate (mm/hr)', fontsize=11)\n",
    "    axes[idx].set_ylabel('Residuals (mm/hr)', fontsize=11)\n",
    "    axes[idx].set_title(f'{model_name} - Residual Plot', fontsize=12, fontweight='bold')\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "After running all the models, analyze your results by answering the following questions:\n",
    "\n",
    "### Question 2: Linear Regression vs Baseline\n",
    "Compare R\u00b2 and RMSE between linear regression and baseline models. Does using all 6 radar parameters improve predictions over just using Zh?\n",
    "\n",
    "### Question 3: Polynomial Regression\n",
    "What polynomial degree performed best? Does it beat the baseline and linear models? Is there overfitting (train vs test performance)?\n",
    "\n",
    "### Question 4: Random Forest\n",
    "What hyperparameters were optimal? Which features were most important? Does Random Forest perform best?\n",
    "\n",
    "### Overall Conclusion\n",
    "Which model is best for predicting rain rate from radar parameters?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}